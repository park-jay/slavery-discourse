{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "982b53b0-d433-4ab6-bdbe-d1ee1c743ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c667525-1915-4109-b40a-4258937652cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop=stopwords.words('english')\n",
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adf3ed62-3c48-4dad-b805-15095d905777",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)  # or 1000\n",
    "pd.set_option('display.max_rows', 100)  # or 1000\n",
    "pd.set_option('display.max_colwidth', 200)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "caf4c77b-4e78-4284-8ab6-0d9d5b2ef4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('/Users/mstudio/repository/viraltext/snippet-fasttext/two_extended_abbeville_banner_slave.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d50c083b-2470-4e5d-a3bd-9e679f0c8a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/mstudio/repository/viraltext/snippet-fasttext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7255bdbc-dc04-4158-89f1-bebea9054455",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]/var/folders/3_/r8z51q092v566bd_r0g_zj640000gn/T/ipykernel_977/2480336597.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  dataframe['punct']=dataframe['stopword'].str.replace('[^\\w\\s]','')\n",
      "100%|███████████████████████████████████████| 3/3 [11:37:59<00:00, 13959.86s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(os.listdir()):\n",
    "    if i.endswith('.csv'):\n",
    "        data=lemmatization(pd.read_csv(i))\n",
    "        data['5-gram']=data['lemma'].apply(lambda x: get_ngrams(x, 5))\n",
    "        reuse=reuse_df(data)\n",
    "        outname='reuse_'+i.lstrip('two_extended_').rstrip('.csv')+'.csv'\n",
    "        outdir='/Users/mstudio/repository/viraltext/reuse/'\n",
    "        if not os.path.exists(outdir):\n",
    "            os.mkdir(outdir)\n",
    "        fullname=os.path.join(outdir, outname)\n",
    "        reuse.to_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb75ad18-dcdb-408b-a81b-0b4b50ae95c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(dataframe:pd.DataFrame()):\n",
    "    dataframe['stopword']=dataframe['context'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "    dataframe['punct']=dataframe['stopword'].str.replace('[^\\w\\s]','')\n",
    "    dataframe['lower']=dataframe['punct'].str.lower()\n",
    "    dataframe['lemma']=dataframe['lower'].apply(lambda row: ' '.join([w.lemma_ for w in nlp(row)]))\n",
    "    dataframe['token']=dataframe['lemma'].apply(word_tokenize)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce69faa4-49cd-4030-b567-c6129fafa0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3_/r8z51q092v566bd_r0g_zj640000gn/T/ipykernel_1754/2480336597.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  dataframe['punct']=dataframe['stopword'].str.replace('[^\\w\\s]','')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.6 s, sys: 24.2 ms, total: 10.6 s\n",
      "Wall time: 10.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data=lemmatization(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bab4ee4c-cecf-4c0e-8ecf-35d88f1730a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "\n",
    "def get_ngrams(text, n):\n",
    "    entire=[]\n",
    "    n_grams=ngrams(word_tokenize(text), n)\n",
    "    for i in n_grams:\n",
    "        entire.append(i)\n",
    "    return entire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "13e8aac1-3d99-42fc-93d0-f8db643c9104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42742, 9)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bd9b2c-4c5b-41e5-82e8-866098895707",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data=data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6237da-f371-47a8-995f-a0783a10f8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 'need', 'your'),\n",
       " ('need', 'your', 'love'),\n",
       " ('your', 'love', ','),\n",
       " ('love', ',', 'i'),\n",
       " (',', 'i', 'need'),\n",
       " ('i', 'need', 'your'),\n",
       " ('need', 'your', 'time')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ngrams('i need your love, i need your time', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "703bcb76-d20b-418d-9ffa-9f5effb4759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['5-gram']=data['lemma'].apply(lambda x: get_ngrams(x, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23aa5133-67a3-4066-8b9f-2ea1d75f33f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('actually', 'perpetrate', 'south', 'institution', 'slavery'),\n",
       " ('perpetrate', 'south', 'institution', 'slavery', 'exclude'),\n",
       " ('south', 'institution', 'slavery', 'exclude', 'every'),\n",
       " ('institution', 'slavery', 'exclude', 'every', 'foot'),\n",
       " ('slavery', 'exclude', 'every', 'foot', 'territory'),\n",
       " ('exclude', 'every', 'foot', 'territory', 'acquire')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['5-gram'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d030dc-1ffa-47eb-8212-9483fd869851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('institution', 'slavery', 'exclude', 'every', 'foot'),\n",
       " ('south', 'institution', 'slavery', 'exclude', 'every'),\n",
       " ('slavery', 'exclude', 'every', 'foot', 'territory'),\n",
       " ('exclude', 'every', 'foot', 'territory', 'acquire'),\n",
       " ('perpetrate', 'south', 'institution', 'slavery', 'exclude'),\n",
       " ('actually', 'perpetrate', 'south', 'institution', 'slavery')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(data['5-gram'][0]).intersection(data['5-gram'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4d5e9b-a1d6-4bae-881a-bd14d7564847",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=[\n",
    "('perpetrate', 'south', 'institution', 'slavery', 'exclude'),\n",
    "('people', 'in', 'the', 'house', 'sleep')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c11b8ef-e81f-47a1-9d0d-efa3b5c0ccfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('perpetrate', 'south', 'institution', 'slavery', 'exclude')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(data['5-gram'][0]).intersection(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f199fba7-a402-4594-8152-2daa44d7161a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('actually', 'perpetrate', 'south', 'institution', 'slavery'),\n",
       " ('perpetrate', 'south', 'institution', 'slavery', 'exclude'),\n",
       " ('south', 'institution', 'slavery', 'exclude', 'every'),\n",
       " ('institution', 'slavery', 'exclude', 'every', 'foot'),\n",
       " ('slavery', 'exclude', 'every', 'foot', 'territory'),\n",
       " ('exclude', 'every', 'foot', 'territory', 'acquire')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['5-gram'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fec2cc7-1825-44b0-9bc3-e0ea4baac1f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reuse_df(data:pd.DataFrame()):\n",
    "    no_reuse=[]\n",
    "    pair_index1=[]\n",
    "    pair_index2=[]\n",
    "    pair_date1=[]\n",
    "    pair_date2=[]\n",
    "    pair_text1=[]\n",
    "    pair_text2=[]\n",
    "    for k in range(0,data.shape[0]):\n",
    "        t=0\n",
    "        for p in range(t,data.shape[0]):\n",
    "            t+=1\n",
    "            if t>k:\n",
    "                if (k==p) & (len(list(set(data['5-gram'][k]).intersection(data['5-gram'][p]))) == len(data['5-gram'][k])):\n",
    "                    pass\n",
    "                elif len(list(set(data['5-gram'][k]).intersection(data['5-gram'][p]))) == 0:\n",
    "                    pass\n",
    "                elif len(list(set(data['5-gram'][k]).intersection(data['5-gram'][p]))) >= 3:\n",
    "                    no_reuse.append(len(list(set(data['5-gram'][k]).intersection(data['5-gram'][p]))))\n",
    "                    pair_index1.append(k) \n",
    "                    pair_index2.append(p)\n",
    "                    pair_date1.append(data.iloc[k]['date'])\n",
    "                    pair_date2.append(data.iloc[p]['date'])\n",
    "                    pair_text1.append(data.iloc[k]['lemma'])\n",
    "                    pair_text2.append(data.iloc[p]['lemma'])\n",
    "    return pd.DataFrame({'no_reuse':no_reuse, 'pair_index1':pair_index1, 'pair_index2':pair_index2, \n",
    "             'pair_date1':pair_date1, 'pair_date2':pair_date2, \n",
    "              'pair_text1':pair_text1, 'pair_text2':pair_text2\n",
    "             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d67ac27f-ffbe-47b6-981a-d7e6041b1d1d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_reuse</th>\n",
       "      <th>pair_index1</th>\n",
       "      <th>pair_index2</th>\n",
       "      <th>pair_date1</th>\n",
       "      <th>pair_date2</th>\n",
       "      <th>pair_text1</th>\n",
       "      <th>pair_text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>136</td>\n",
       "      <td>1856-08-21-seq-4.txt</td>\n",
       "      <td>1856-09-18-seq-4.txt</td>\n",
       "      <td>penetrate it lie political liberal owe 110 slavish sorvilc allegiance party politician it advocate measure man</td>\n",
       "      <td>penetrate it political liberal owe slavish servile allegiance party politician it advocate measure man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>283</td>\n",
       "      <td>1856-08-21-seq-4.txt</td>\n",
       "      <td>1856-05-08-seq-4.txt</td>\n",
       "      <td>penetrate it lie political liberal owe 110 slavish sorvilc allegiance party politician it advocate measure man</td>\n",
       "      <td>penetrate it political liberal owe slavish servile allegiance party politician it advocate measure man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>618</td>\n",
       "      <td>1856-08-21-seq-4.txt</td>\n",
       "      <td>1856-06-05-seq-4.txt</td>\n",
       "      <td>penetrate it lie political liberal owe 110 slavish sorvilc allegiance party politician it advocate measure man</td>\n",
       "      <td>penetrate it political liberal owe slavish servile allegiance party politician it advocate measure man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>723</td>\n",
       "      <td>1856-08-21-seq-4.txt</td>\n",
       "      <td>1856-02-28-seq-4.txt</td>\n",
       "      <td>penetrate it lie political liberal owe 110 slavish sorvilc allegiance party politician it advocate measure man</td>\n",
       "      <td>penetrate it politioul liberal owe uc slavish servile allegiance party politician it advocate measure man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>1024</td>\n",
       "      <td>1856-08-21-seq-4.txt</td>\n",
       "      <td>1856-06-26-seq-4.txt</td>\n",
       "      <td>penetrate it lie political liberal owe 110 slavish sorvilc allegiance party politician it advocate measure man</td>\n",
       "      <td>ponetrate it political liherul owe slavish rervile allegiance party politician it advocate measure man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>4</td>\n",
       "      <td>2552</td>\n",
       "      <td>2553</td>\n",
       "      <td>1858-03-25-seq-1.txt</td>\n",
       "      <td>1858-03-25-seq-1.txt</td>\n",
       "      <td>the law utah true recognize   provide slavery hut slave lbefc jutuh technically slave</td>\n",
       "      <td>provide slavery hut slave lbefc jutuh technically slave   owmwpitjj actually free community j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>3</td>\n",
       "      <td>2608</td>\n",
       "      <td>2609</td>\n",
       "      <td>1856-02-14-seq-2.txt</td>\n",
       "      <td>1856-02-14-seq-2.txt</td>\n",
       "      <td>tion tlie cnsiirtin f friend 1 firslshould kansas tie make u slave c state we say location climate soil w</td>\n",
       "      <td>state we say location climate soil w production value f slave lahor tlie good master si iveall conspire h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>7</td>\n",
       "      <td>2615</td>\n",
       "      <td>2616</td>\n",
       "      <td>1856-02-14-seq-2.txt</td>\n",
       "      <td>1856-02-14-seq-2.txt</td>\n",
       "      <td>dom lawrence t secondlycan kansas lie make slave h state thus far proslavery party</td>\n",
       "      <td>secondlycan kansas lie make slave h state thus far proslavery party triumph kmsa spile a ho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>7</td>\n",
       "      <td>2660</td>\n",
       "      <td>2661</td>\n",
       "      <td>1858-04-29-seq-2.txt</td>\n",
       "      <td>1858-04-29-seq-2.txt</td>\n",
       "      <td>decision terrritory remain territorial condition slave territory amd thfat southern man may carry slave</td>\n",
       "      <td>territorial condition slave territory amd thfat southern man may carry slave there friend freedom emphatically</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>3</td>\n",
       "      <td>2680</td>\n",
       "      <td>2681</td>\n",
       "      <td>1856-10-02-seq-2.txt</td>\n",
       "      <td>1856-10-02-seq-2.txt</td>\n",
       "      <td>ny decide conviction kansas would 10 slaveholde slate that I anx in i d ouiuiicrii man emigrate mere</td>\n",
       "      <td>in i d ouiuiicrii man emigrate mere   villi family slave man rould cut forest plough</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>343 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     no_reuse  pair_index1  pair_index2            pair_date1  \\\n",
       "0           3           15          136  1856-08-21-seq-4.txt   \n",
       "1           3           15          283  1856-08-21-seq-4.txt   \n",
       "2           3           15          618  1856-08-21-seq-4.txt   \n",
       "3           3           15          723  1856-08-21-seq-4.txt   \n",
       "4           3           15         1024  1856-08-21-seq-4.txt   \n",
       "..        ...          ...          ...                   ...   \n",
       "338         4         2552         2553  1858-03-25-seq-1.txt   \n",
       "339         3         2608         2609  1856-02-14-seq-2.txt   \n",
       "340         7         2615         2616  1856-02-14-seq-2.txt   \n",
       "341         7         2660         2661  1858-04-29-seq-2.txt   \n",
       "342         3         2680         2681  1856-10-02-seq-2.txt   \n",
       "\n",
       "               pair_date2  \\\n",
       "0    1856-09-18-seq-4.txt   \n",
       "1    1856-05-08-seq-4.txt   \n",
       "2    1856-06-05-seq-4.txt   \n",
       "3    1856-02-28-seq-4.txt   \n",
       "4    1856-06-26-seq-4.txt   \n",
       "..                    ...   \n",
       "338  1858-03-25-seq-1.txt   \n",
       "339  1856-02-14-seq-2.txt   \n",
       "340  1856-02-14-seq-2.txt   \n",
       "341  1858-04-29-seq-2.txt   \n",
       "342  1856-10-02-seq-2.txt   \n",
       "\n",
       "                                                                                                         pair_text1  \\\n",
       "0    penetrate it lie political liberal owe 110 slavish sorvilc allegiance party politician it advocate measure man   \n",
       "1    penetrate it lie political liberal owe 110 slavish sorvilc allegiance party politician it advocate measure man   \n",
       "2    penetrate it lie political liberal owe 110 slavish sorvilc allegiance party politician it advocate measure man   \n",
       "3    penetrate it lie political liberal owe 110 slavish sorvilc allegiance party politician it advocate measure man   \n",
       "4    penetrate it lie political liberal owe 110 slavish sorvilc allegiance party politician it advocate measure man   \n",
       "..                                                                                                              ...   \n",
       "338                           the law utah true recognize   provide slavery hut slave lbefc jutuh technically slave   \n",
       "339       tion tlie cnsiirtin f friend 1 firslshould kansas tie make u slave c state we say location climate soil w   \n",
       "340                              dom lawrence t secondlycan kansas lie make slave h state thus far proslavery party   \n",
       "341         decision terrritory remain territorial condition slave territory amd thfat southern man may carry slave   \n",
       "342            ny decide conviction kansas would 10 slaveholde slate that I anx in i d ouiuiicrii man emigrate mere   \n",
       "\n",
       "                                                                                                         pair_text2  \n",
       "0            penetrate it political liberal owe slavish servile allegiance party politician it advocate measure man  \n",
       "1            penetrate it political liberal owe slavish servile allegiance party politician it advocate measure man  \n",
       "2            penetrate it political liberal owe slavish servile allegiance party politician it advocate measure man  \n",
       "3         penetrate it politioul liberal owe uc slavish servile allegiance party politician it advocate measure man  \n",
       "4            ponetrate it political liherul owe slavish rervile allegiance party politician it advocate measure man  \n",
       "..                                                                                                              ...  \n",
       "338                   provide slavery hut slave lbefc jutuh technically slave   owmwpitjj actually free community j  \n",
       "339       state we say location climate soil w production value f slave lahor tlie good master si iveall conspire h  \n",
       "340                     secondlycan kansas lie make slave h state thus far proslavery party triumph kmsa spile a ho  \n",
       "341  territorial condition slave territory amd thfat southern man may carry slave there friend freedom emphatically  \n",
       "342                            in i d ouiuiicrii man emigrate mere   villi family slave man rould cut forest plough  \n",
       "\n",
       "[343 rows x 7 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'no_reuse':no_reuse, 'pair_index1':pair_index1, 'pair_index2':pair_index2, \n",
    "             'pair_date1':pair_date1, 'pair_date2':pair_date2, \n",
    "              'pair_text1':pair_text1, 'pair_text2':pair_text2\n",
    "             })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
